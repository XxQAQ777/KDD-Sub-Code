# NPY文件第二维（num_samples）详细说明

## 问题：第二维是什么？

生成的NPY文件形状为 `(seq_length, num_samples, num_nodes)`，其中第二维 `num_samples` 是**测试集中的样本数量**。

## 详细解释

### 1. 数据来源

第二维来自于 `test.npz` 文件中的样本数量：

```python
# 从 data_loader.py 第100-102行
cat_data = np.load(os.path.join(dataset_dir, 'test.npz'))
data['x_test'] = cat_data['x']   # (num_samples, window, num_nodes, feature_dim)
data['y_test'] = cat_data['y']   # (num_samples, horizon, num_nodes, feature_dim)
```

### 2. 样本的定义

每个样本是一个**滑动窗口**：
- **输入 (x)**: 过去144个时间步的数据 (window=144)
- **输出 (y)**: 未来144个时间步的数据 (horizon=144)

例如：
- 样本0: 使用时间步 [0:144] 预测 [144:288]
- 样本1: 使用时间步 [1:145] 预测 [145:289]
- 样本2: 使用时间步 [2:146] 预测 [146:290]
- ...

### 3. 样本数量的计算

样本数量取决于：
- 测试集的总时间步数
- 滑动窗口的大小 (window=144)
- 预测时间步数 (horizon=144)

**公式**:
```
num_samples = total_timesteps - window - horizon + 1
```

或者更简单地说：
```
num_samples = 测试集中可以构造的滑动窗口数量
```

### 4. 在test_and_plot.py中的处理

```python
# 第193-194行：加载测试数据
realy = torch.Tensor(data_loader['y_test']).to(args.device)
realy = realy[:, :, :, 0:1]  # (B, T, N, 1)
# B = num_samples (批次维度，即样本数量)
# T = horizon (144个时间步)
# N = num_nodes (节点数量)
```

```python
# 第198-206行：批次预测
outputs = []
with torch.no_grad():
    for _, (x, y) in enumerate(test_loader.get_iterator()):
        testx = torch.Tensor(x).to(args.device)
        output = model(testx[:, :, :, :args.input_dim])
        outputs.append(output)

# 合并所有批次的预测结果
yhat = torch.cat(outputs, dim=0)  # (num_samples, horizon, num_nodes, 1)
yhat = yhat[:realy.size(0), ...]
```

```python
# 第222-244行：按时间步处理
for i in range(args.horizon):  # 遍历144个时间步
    pred = scaler.inverse_transform(yhat[:, i, :, :])  # (num_samples, num_nodes, 1)
    real = realy[:, i, :, :]  # (num_samples, num_nodes, 1)

    # 保存每个时间步的所有样本预测
    predictions.append(pred.cpu().numpy())  # (num_samples, num_nodes, 1)
    ground_truth.append(real.cpu().numpy())  # (num_samples, num_nodes, 1)

# 第251-252行：转换为最终格式
predictions = np.array(predictions)  # (T, B, N, 1) -> (144, num_samples, num_nodes, 1)
ground_truth = np.array(ground_truth)  # (T, B, N, 1) -> (144, num_samples, num_nodes, 1)
```

### 5. 在generate_predictions_npy.py中的处理

```python
# 第169-180行：按时间步收集预测
for i in range(args.horizon):
    # 反归一化预测结果
    pred = scaler.inverse_transform(yhat[:, i, :, :])  # (num_samples, num_nodes, 1)
    real = realy[:, i, :, :]  # (num_samples, num_nodes, 1)

    # 移除最后一维并转换为numpy
    pred_np = pred.squeeze(-1).cpu().numpy()  # (num_samples, num_nodes)
    real_np = real.squeeze(-1).cpu().numpy()  # (num_samples, num_nodes)

    predictions_list.append(pred_np)
    ground_truth_list.append(real_np)

# 第183-184行：堆叠为最终格式
predictions = np.stack(predictions_list, axis=0)  # (seq_length, num_samples, num_nodes)
ground_truth = np.stack(ground_truth_list, axis=0)  # (seq_length, num_samples, num_nodes)
```

## 实际例子

### PEMSBAY数据集
假设测试集有 `test.npz`:
- `x_test.shape = (5209, 144, 325, 1)`
- `y_test.shape = (5209, 144, 325, 1)`

那么：
- **num_samples = 5209** (测试集中有5209个滑动窗口样本)
- **seq_length = 144** (每个样本预测144个时间步)
- **num_nodes = 325** (PEMSBAY有325个传感器节点)

生成的NPY文件：
- `stgcn_pemsbay_predictions.npy`: **(144, 5209, 325)**
- `pemsbay_ground_truth.npy`: **(144, 5209, 325)**

### METRLA数据集
假设测试集有 `test.npz`:
- `x_test.shape = (num_samples, 144, 207, 1)`
- `y_test.shape = (num_samples, 144, 207, 1)`

那么：
- **num_samples = 测试集样本数** (具体数量取决于数据集)
- **seq_length = 144**
- **num_nodes = 207** (METRLA有207个传感器节点)

生成的NPY文件：
- `stgcn_metrla_predictions.npy`: **(144, num_samples, 207)**
- `metrla_ground_truth.npy`: **(144, num_samples, 207)**

## 如何使用第二维

### 访问特定样本的预测
```python
import numpy as np

# 加载预测结果
predictions = np.load('predictions_npy/stgcn_pemsbay_predictions.npy')
# Shape: (144, 5209, 325)

# 访问第100个样本的所有时间步预测
sample_100 = predictions[:, 100, :]  # Shape: (144, 325)
# 这是第100个滑动窗口的144个时间步预测

# 访问第100个样本在第10个时间步的预测
sample_100_t10 = predictions[10, 100, :]  # Shape: (325,)
# 这是第100个样本在第10个时间步的所有节点预测
```

### 计算每个样本的误差
```python
import numpy as np

predictions = np.load('predictions_npy/stgcn_pemsbay_predictions.npy')
ground_truth = np.load('predictions_npy/pemsbay_ground_truth.npy')

# 计算每个样本的平均MAE
sample_mae = np.mean(np.abs(predictions - ground_truth), axis=(0, 2))
# Shape: (5209,) - 每个样本的MAE

# 找出误差最大的样本
worst_sample_idx = np.argmax(sample_mae)
print(f"误差最大的样本索引: {worst_sample_idx}")
print(f"该样本的MAE: {sample_mae[worst_sample_idx]:.4f}")

# 找出误差最小的样本
best_sample_idx = np.argmin(sample_mae)
print(f"误差最小的样本索引: {best_sample_idx}")
print(f"该样本的MAE: {sample_mae[best_sample_idx]:.4f}")
```

### 计算每个时间步的平均误差
```python
# 计算每个时间步在所有样本上的平均MAE
timestep_mae = np.mean(np.abs(predictions - ground_truth), axis=(1, 2))
# Shape: (144,) - 每个时间步的MAE

# 绘制误差随时间步的变化
import matplotlib.pyplot as plt
plt.plot(range(1, 145), timestep_mae)
plt.xlabel('Time Step')
plt.ylabel('MAE')
plt.title('MAE vs Time Step (averaged over all samples)')
plt.show()
```

## 总结

**第二维 `num_samples` 表示**:
- 测试集中的样本数量
- 每个样本是一个滑动窗口（使用过去144步预测未来144步）
- 样本数量由测试集的总时间步数和滑动窗口大小决定
- 对于PEMSBAY，通常有5000+个测试样本
- 对于METRLA，样本数量取决于具体的数据集划分

**维度含义总结**:
- **第一维 (seq_length=144)**: 预测的时间步数（未来144个时间点）
- **第二维 (num_samples)**: 测试集中的样本数量（滑动窗口数量）
- **第三维 (num_nodes)**: 图中的节点数量（传感器数量）

这种格式允许你：
1. 分析不同时间步的预测性能
2. 分析不同样本的预测性能
3. 分析不同节点的预测性能
4. 进行各种统计分析和可视化
